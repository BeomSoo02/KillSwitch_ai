# app.py â€” KillSwitch AI (ê°•ì œ trailing-dot + ëª¨ë¸ ì ìˆ˜ë§Œ + í‚¤ ìƒíƒœ)
# -------------------------------------------------------------------

import os, re, unicodedata, time
import streamlit as st

st.set_page_config(page_title="KillSwitch AI", layout="wide")

# âœ… í™˜ê²½/ì‹œí¬ë¦¿ ì„¤ì •
DEFAULT_REPO_ID   = "cookiechips/KillSwitch_ai"
DEFAULT_REPO_TYPE = "model"
DEFAULT_FILENAME  = "prompt_guard_best.pt"

REPO_ID   = st.secrets.get("HF_REPO_ID")   or os.getenv("HF_REPO_ID")   or DEFAULT_REPO_ID
REPO_TYPE = st.secrets.get("HF_REPO_TYPE") or os.getenv("HF_REPO_TYPE") or DEFAULT_REPO_TYPE
FILENAME  = "prompt_guard_best.pt"
HF_TOKEN  = st.secrets.get("HF_TOKEN")     or os.getenv("HF_TOKEN")
HF_DIR    = st.secrets.get("HF_DIR")

BASE_MODEL = "microsoft/deberta-v3-base"
NUM_LABELS = 2

# âœ… ëª¨ë¸ ë¡œë“œ
import torch
from huggingface_hub import hf_hub_download
from transformers import AutoTokenizer, AutoModelForSequenceClassification

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

@st.cache_resource
def get_ckpt_path():
    try:
        return hf_hub_download(repo_id=REPO_ID, filename=FILENAME,
                               repo_type=REPO_TYPE, token=HF_TOKEN)
    except:
        return hf_hub_download(repo_id=REPO_ID, filename=FILENAME,
                               repo_type="dataset", token=HF_TOKEN)

@st.cache_resource
def load_model_tokenizer():
    tok = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=False)

    mdl = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=NUM_LABELS)
    try:
        ckpt = torch.load(get_ckpt_path(), map_location="cpu")
        mdl.load_state_dict(ckpt.get("model", ckpt), strict=False)
    except Exception as e:
        st.error("ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨ â€” ëª¨ë¸ ë¯¸ë¡œë”©")
        st.caption(str(e))

    return mdl.to(DEVICE).eval(), tok

mdl, tok = load_model_tokenizer()

# âœ… ì „ì²˜ë¦¬ + ëë§ˆì¹¨í‘œ ê°•ì œ only
def preprocess(s: str) -> str:
    s = unicodedata.normalize("NFKC", s or "")
    s = re.sub(r"\s+", " ", s).strip()
    return s if s.endswith(".") else s + "."

@torch.no_grad()
def score(text):
    enc = tok(text, return_tensors="pt", truncation=True, padding=True, max_length=256)
    logits = mdl(**{k: v.to(DEVICE) for k, v in enc.items()}).logits
    if logits.size(-1) == 1:
        return torch.sigmoid(logits)[0,0].item()
    return torch.softmax(logits, dim=-1)[0,1].item()

def predict(text, thr):
    text = preprocess(text)
    t0 = time.time()
    s = score(text)
    label = "ì•…ì„±" if s >= thr else "ì•ˆì „"
    return {
        "ì ìˆ˜": round(s,3),
        "ì„ê³„ê°’": round(thr,3),
        "íŒì •": label,
        "_elapsed_s": round(time.time() - t0, 2),
    }

# âœ… UI â€” í‚¤ ìƒíƒœ / ì˜µì…˜
st.title("ğŸ›¡ï¸ KillSwitch AI")

if "OPENAI_API_KEY" not in st.session_state:
    st.session_state.OPENAI_API_KEY = ""

with st.sidebar.expander("ğŸ” í‚¤ ìƒíƒœ"):
    key_ok = any([
        bool(st.secrets.get("OPENAI_API_KEY")),
        bool(os.getenv("OPENAI_API_KEY")),
        bool(st.session_state.get("OPENAI_API_KEY"))
    ])
    st.write("OpenAI Key:", "âœ… ê°ì§€ë¨" if key_ok else "âŒ ì—†ìŒ")

OPENAI_API_KEY = st.sidebar.text_input(
    "OPENAI_API_KEY", value=st.session_state.OPENAI_API_KEY, type="password"
)
st.session_state.OPENAI_API_KEY = OPENAI_API_KEY

openai_model = st.sidebar.text_input("OpenAI ëª¨ë¸", value="gpt-4o-mini")
thr_ui = st.sidebar.slider("ì„ê³„ê°’(ì°¨ë‹¨ ê¸°ì¤€)", 0.05, 0.95, 0.5, step=0.05)
force_call = st.sidebar.checkbox("ìœ„í—˜í•´ë„ GPT í˜¸ì¶œ ê°•í–‰")

st.sidebar.caption(f"HF: {REPO_ID} / {FILENAME}")
if st.sidebar.button("HF ì—°ê²° ì ê²€"):
    try:
        p = get_ckpt_path()
        st.sidebar.success(f"OK {os.path.basename(p)}")
    except Exception as e:
        st.sidebar.error("ì‹¤íŒ¨")
        st.sidebar.caption(str(e))

# âœ… ì…ë ¥/ì‹¤í–‰
txt = st.text_area("í”„ë¡¬í”„íŠ¸", height=140)
if st.button("ë¶„ì„ (GPT í˜¸ì¶œ)"):
    result = predict(txt, thr_ui)
    st.subheader("ë¶„ì„ ê²°ê³¼")
    st.json(result)

    st.subheader("GPT ì‘ë‹µ")
    if not st.session_state.OPENAI_API_KEY:
        st.info("API KEY ì—†ìŒ â†’ GPT í˜¸ì¶œ ìƒëµ")
    elif result["íŒì •"] == "ì•…ì„±" and not force_call:
        st.warning("ì•…ì„± íŒì • â†’ GPT í˜¸ì¶œ ì°¨ë‹¨ë¨")
    else:
        try:
            from openai import OpenAI
            client = OpenAI(api_key=st.session_state.OPENAI_API_KEY)
            rsp = client.responses.create(
                model=openai_model,
                input=[{"role":"user","content":txt}],
                temperature=0.3
            )
            st.write(rsp.output_text)
        except Exception as e:
            st.error(str(e))
