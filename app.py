import streamlit as st
import torch
from utils import load_classifier, predict_one
from config import MODEL_NAME, CHECKPOINT_PATH, DEFAULT_THRESHOLD, MAX_LEN

st.set_page_config(page_title='KillSwitch AI â€” Prompt Guard (Classifier)', page_icon='ğŸ›¡ï¸')
st.title('ğŸ›¡ï¸ KillSwitch AI â€” Prompt Guard (Classifier)')
@st.cache_resource(show_spinner=True)
def get_runtime():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    tok, model, best_thr = load_classifier(MODEL_NAME, CHECKPOINT_PATH, device=device)
    return tok, model, device, best_thr
tok, model, device, best_thr = get_runtime()
with st.sidebar:
    base_thr = best_thr if best_thr is not None else DEFAULT_THRESHOLD
    thr = st.slider('Decision threshold', 0.50, 0.99, float(base_thr), 0.01)
    st.write(f'Device: {device}')
txt = st.text_area('í”„ë¡¬í”„íŠ¸', height=150)
if st.button('ë¶„ì„í•˜ê¸°', type='primary'):
    if not txt.strip(): st.warning('ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”.')
    else:
        y, p = predict_one(txt, *get_runtime()[:2], threshold=thr, max_len=MAX_LEN, device=device)
        st.write(f'ì•…ì„± í™•ë¥ : {p:.4f}'); st.write('íŒì •: ' + ('ğŸš« ì•…ì„±' if y else 'âœ… ì •ìƒ'))
